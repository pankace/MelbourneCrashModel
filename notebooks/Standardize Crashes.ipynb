{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "city = 'Melbourne'\n",
    "CITY_DIR = os.path.join(DATA_DIR, city) \n",
    "RAW_DIR = os.path.join(CITY_DIR, 'raw')\n",
    "RAW_CRASH_DIR = os.path.join(RAW_DIR, 'crash')\n",
    "PROCESSED_CRASH_DIR = os.path.join(CITY_DIR, 'processed', 'crash')\n",
    "PROCESSED_MAPPING_DIR = os.path.join(CITY_DIR, 'processed', 'mapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get file names and read in csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_file = os.path.join(RAW_CRASH_DIR, 'crash.csv')\n",
    "map_file = os.path.join(RAW_CRASH_DIR, 'map.csv')\n",
    "map_inters_file = os.path.join(RAW_CRASH_DIR, 'map_inters.csv')\n",
    "atmosphere_file = os.path.join(RAW_CRASH_DIR, 'atmosphere.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crash_df = pd.read_csv(crash_file)\n",
    "map_df = pd.read_csv(map_file)\n",
    "map_inters_df = pd.read_csv(map_inters_file)\n",
    "atmosphere_df = pd.read_csv(atmosphere_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crash_df: drop unwanted columns and establish mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df_cols = list(crash_df.columns.values)\n",
    "crash_df_cols_reduced = ['ACCIDENT_NO','ACCIDENTDATE','ACCIDENTTIME','DAY_OF_WEEK','LIGHT_CONDITION','NODE_ID',\n",
    "                      'ROAD_GEOMETRY','SPEED_ZONE']\n",
    "geom_mapping_cols = ['ROAD_GEOMETRY', 'Road Geometry Desc']\n",
    "accident_type_mapping_cols = ['ACCIDENT_TYPE', 'Accident Type Desc']\n",
    "DCA_code_mapping_cols = ['DCA_CODE', 'DCA Description']\n",
    "light_condition_mapping_cols = ['LIGHT_CONDITION', 'Light Condition Desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_mapping = crash_df[geom_mapping_cols]\n",
    "geom_mapping = geom_mapping.drop_duplicates().sort_values(by='ROAD_GEOMETRY').reset_index(drop=True)\n",
    "\n",
    "accident_type_mapping = crash_df[accident_type_mapping_cols]\n",
    "accident_type_mapping = accident_type_mapping.drop_duplicates().sort_values(by='ACCIDENT_TYPE').reset_index(drop=True)\n",
    "\n",
    "light_condition_mapping = crash_df[light_condition_mapping_cols]\n",
    "light_condition_mapping = light_condition_mapping.drop_duplicates().sort_values(by='LIGHT_CONDITION').reset_index(drop=True)\n",
    "\n",
    "DCA_code_mapping = crash_df[DCA_code_mapping_cols]\n",
    "DCA_code_mapping = DCA_code_mapping.drop_duplicates().sort_values(by=\"DCA_CODE\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crash_df_reduced = crash_df[crash_df_cols_reduced]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map_df: drop unwanted columns, create node type mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type_mapping = pd.DataFrame({'NODE_TYPE_INT': [0, 1, 2, 3], 'NODE_TYPE': ['I', 'N', 'O', 'U'], \n",
    "                                  'NODE_DESC': ['Intersection', 'Non-intersection', 'Off-road', 'Unknown']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df['NODE_TYPE_INT'] = \"\"\n",
    "for index, row in node_type_mapping.iterrows():\n",
    "    map_df['NODE_TYPE_INT'].loc[map_df['NODE_TYPE'] == row['NODE_TYPE']]  = row['NODE_TYPE_INT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df_reduced_cols = ['ACCIDENT_NO', 'NODE_ID', 'NODE_TYPE_INT', 'LGA_NAME', 'Deg Urban Name', 'Lat', 'Long']\n",
    "map_df_reduced = map_df[map_df_reduced_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map_inters_df: drop unwanted columns, create node to complex node mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_node_mapping_cols = ['NODE_ID', 'COMPLEX_INT_NO']\n",
    "complex_node_mapping = map_inters_df[complex_node_mapping_cols]\n",
    "complex_node_mapping = complex_node_mapping.drop_duplicates().sort_values(by=\"NODE_ID\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_inters_df_reduced = map_inters_df[['ACCIDENT_NO', 'COMPLEX_INT_NO']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## atmosphere_df: drop unwanted columns, create atmosphere mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "atmosphere_mapping_cols = ['ATMOSPH_COND', 'Atmosph Cond Desc']\n",
    "atmosphere_mapping = atmosphere_df[atmosphere_mapping_cols]\n",
    "atmosphere_mapping = atmosphere_mapping.drop_duplicates().sort_values(by=\"ATMOSPH_COND\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "atmosphere_df_reduced_cols = ['ACCIDENT_NO', 'ATMOSPH_COND']\n",
    "atmosphere_df_reduced = atmosphere_df[atmosphere_df_reduced_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates from all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df_reduced.drop_duplicates(subset=\"ACCIDENT_NO\", inplace=True)\n",
    "map_df_reduced.drop_duplicates(subset=\"ACCIDENT_NO\", inplace=True)\n",
    "map_inters_df_reduced.drop_duplicates(subset=\"ACCIDENT_NO\", inplace=True)\n",
    "atmosphere_df_reduced.drop_duplicates(subset=\"ACCIDENT_NO\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crashes_df: join all of above dataframes on 'accident_no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crashes_df: cleanup, add derived features, rename, validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCIDENT_NO</th>\n",
       "      <th>ACCIDENT_DATE</th>\n",
       "      <th>ACCIDENT_TIME</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>LIGHT_CONDITION</th>\n",
       "      <th>NODE_ID</th>\n",
       "      <th>ROAD_GEOMETRY</th>\n",
       "      <th>SPEED_ZONE</th>\n",
       "      <th>ATMOSPH_COND</th>\n",
       "      <th>NODE_TYPE_INT</th>\n",
       "      <th>SUBURB</th>\n",
       "      <th>DEGREE_URBAN</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>COMPLEX_INT_NO</th>\n",
       "      <th>COMPLEX_NODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T20060000010</td>\n",
       "      <td>13/01/2006</td>\n",
       "      <td>12.42.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>43078</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DANDENONG</td>\n",
       "      <td>MELB_URBAN</td>\n",
       "      <td>-37.98862</td>\n",
       "      <td>145.21805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T20060000018</td>\n",
       "      <td>13/01/2006</td>\n",
       "      <td>19.10.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>29720</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CASEY</td>\n",
       "      <td>MELB_URBAN</td>\n",
       "      <td>-37.99092</td>\n",
       "      <td>145.27632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T20060000022</td>\n",
       "      <td>14/01/2006</td>\n",
       "      <td>12.10.00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>203074</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MORNINGTON PENINSULA</td>\n",
       "      <td>RURAL_VICTORIA</td>\n",
       "      <td>-38.39632</td>\n",
       "      <td>144.85489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T20060000023</td>\n",
       "      <td>14/01/2006</td>\n",
       "      <td>11.49.00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>55462</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DANDENONG</td>\n",
       "      <td>MELB_URBAN</td>\n",
       "      <td>-37.98918</td>\n",
       "      <td>145.14496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T20060000026</td>\n",
       "      <td>14/01/2006</td>\n",
       "      <td>10.45.00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>202988</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MORNINGTON PENINSULA</td>\n",
       "      <td>MELB_URBAN</td>\n",
       "      <td>-38.37299</td>\n",
       "      <td>144.87159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ACCIDENT_NO ACCIDENT_DATE ACCIDENT_TIME  DAY_OF_WEEK  LIGHT_CONDITION  \\\n",
       "0  T20060000010    13/01/2006      12.42.00            6                1   \n",
       "1  T20060000018    13/01/2006      19.10.00            6                1   \n",
       "2  T20060000022    14/01/2006      12.10.00            7                1   \n",
       "3  T20060000023    14/01/2006      11.49.00            7                1   \n",
       "4  T20060000026    14/01/2006      10.45.00            7                1   \n",
       "\n",
       "   NODE_ID  ROAD_GEOMETRY  SPEED_ZONE  ATMOSPH_COND NODE_TYPE_INT  \\\n",
       "0    43078              1          60             1             0   \n",
       "1    29720              2          70             1             1   \n",
       "2   203074              5         100             1             1   \n",
       "3    55462              2          80             1             0   \n",
       "4   202988              5          50             1             1   \n",
       "\n",
       "                 SUBURB    DEGREE_URBAN       LAT        LON  COMPLEX_INT_NO  \\\n",
       "0             DANDENONG      MELB_URBAN -37.98862  145.21805               0   \n",
       "1                 CASEY      MELB_URBAN -37.99092  145.27632               0   \n",
       "2  MORNINGTON PENINSULA  RURAL_VICTORIA -38.39632  144.85489               0   \n",
       "3             DANDENONG      MELB_URBAN -37.98918  145.14496               0   \n",
       "4  MORNINGTON PENINSULA      MELB_URBAN -38.37299  144.87159               0   \n",
       "\n",
       "   COMPLEX_NODE  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crashes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_df.dropna(subset=['Lat', 'Long'], inplace = True)\n",
    "crashes_df.drop(['NODE_ID_y'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_df.fillna(value=0, inplace=True)\n",
    "crashes_df[['NODE_ID_x', 'COMPLEX_INT_NO']] = crashes_df[['NODE_ID_x', 'COMPLEX_INT_NO']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_df['COMPLEX_NODE'] = 0\n",
    "crashes_df['COMPLEX_NODE'].loc[crashes_df['COMPLEX_INT_NO'] > 0]  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE USE THIS CELL IF BY THE HOUR IS NOT GRANULAR ENOUGH\n",
    "\n",
    "def mapTime(x):\n",
    "    hour = x[:2]\n",
    "    minute = float(x[3:5])\n",
    "    if minute < 30:\n",
    "        minute = 0\n",
    "    else:\n",
    "        minute = 0.5\n",
    "    time = float(hour) + minute\n",
    "    return time\n",
    "\n",
    "crashes_df['HOUR'] = crashes_df['ACCIDENT_TIME'].apply(mapTime)\n",
    "crashes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_df['HOUR'] = crashes_df['ACCIDENT_TIME'].apply(lambda x: x[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_df.rename(columns={\"NODE_ID_x\":\"NODE_ID\", \"ACCIDENTDATE\":\"ACCIDENT_DATE\", \"ACCIDENTTIME\":\"ACCIDENT_TIME\", \n",
    "                           \"LGA_NAME\":\"SUBURB\", \"Deg Urban Name\":\"DEGREE_URBAN\", \"Lat\":\"LAT\", \"Long\":\"LON\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output crashes_df and all mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PROCESSED_CRASH_DIR):\n",
    "    os.makedirs(PROCESSED_CRASH_DIR)\n",
    "\n",
    "if not os.path.exists(PROCESSED_MAPPING_DIR):\n",
    "    os.makedirs(PROCESSED_MAPPING_DIR)\n",
    "    \n",
    "crashes_path = os.path.join(PROCESS_CRASH_DIR, 'crashes.csv')\n",
    "crashes_df.to_csv(crashes_path)\n",
    "    \n",
    "mapping_dfs = [geom_mapping, accident_type_mapping, DCA_code_mapping, \n",
    "               light_condition_mapping, node_type_mapping, atmosphere_mapping]\n",
    "mapping_names = ['geom_mapping.csv', 'accident_type_mapping.csv', 'DCA_code_mapping.csv', \n",
    "               'light_condition_mapping.csv', 'node_type_mapping.csv', 'atmosphere_mapping.csv']\n",
    "\n",
    "for mapping_df, mapping_name in zip(mapping_dfs, mapping_names):\n",
    "    save_path = os.path.join(PROCESSED_MAPPING_DIR, mapping_name)\n",
    "    mapping_df.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame({'Hi': [1,2,3], 'bob': ['a','b', 'c'], 'friend': ['x', 'y', 'z']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.set_index('Hi', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bob</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bob friend\n",
       "Hi           \n",
       "1    a      x\n",
       "2    b      y\n",
       "3    c      z"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\":{\"bob\":\"a\",\"friend\":\"x\"},\"2\":{\"bob\":\"b\",\"friend\":\"y\"},\"3\":{\"bob\":\"c\",\"friend\":\"z\"}}'"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.to_json(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
